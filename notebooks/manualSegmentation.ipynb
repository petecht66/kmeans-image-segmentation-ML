{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb83b6c6-497a-45a6-a4ae-dd3b7f0259be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread, imsave\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16d21da3-57a0-4d4f-9a18-a4c5c210c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of image filenames\n",
    "image_files = [\"images/beacon.JPEG\", \"images/elephant.jpg\", \"images/robin.JPEG\", \"images/vulture.JPEG\"]\n",
    "\n",
    "# declare number of clusters, can change this later\n",
    "k = 10\n",
    "\n",
    "# Declare output folder\n",
    "output_path = \"remadeManualSegmentationImages/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bdf835b-e5c3-490a-a412-03bf3312480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manualKmeans(X, k=4, max_iters=20, tol=1e-4, random_state=42):\n",
    "    # random number generator\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initialize cluster centers randomly from the data\n",
    "    random_idxs = np.random.choice(len(X), size=k, replace=False) # Chat-GPT-3. (2025, Oct. 26)\n",
    "    centers = X[random_idxs]\n",
    "\n",
    "    # Iterate through the data .... Chat-GPT-3. (2025, Oct. 26)\n",
    "    for iteration in range(max_iters):\n",
    "        distances = np.linalg.norm(X[:, np.newaxis] - centers, axis=2)  # (n_samples, k)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "\n",
    "        new_centers = np.array([X[labels == i].mean(axis=0) if np.any(labels == i) else centers[i] for i in range(k)])\n",
    "\n",
    "        center_shift = np.linalg.norm(new_centers - centers)\n",
    "        if center_shift < tol:\n",
    "            break\n",
    "\n",
    "        centers = new_centers\n",
    "\n",
    "    return centers, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3da048e3-c699-4838-bd36-5451cdc9d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First image provided\n",
    "# reading the image\n",
    "img = imread(\"images/beacon.JPEG\")\n",
    "\n",
    "# Convert to 2d form\n",
    "img2d = img.reshape(-1,3).astype(np.float64)\n",
    "\n",
    "# Apply the manual KMeans implementation\n",
    "centers, labels = manualKmeans(img2d, k, max_iters = 10)\n",
    "\n",
    "# Reconstruct image\n",
    "segmented_img = centers[labels].reshape(img.shape)\n",
    "\n",
    "# Fix scaling based on dtype, Chat-GPT-3. (2025, Oct. 26)\n",
    "if img.dtype == np.uint8:\n",
    "    # Input already in 0–255, so don't multiply\n",
    "    segmented_img = np.clip(segmented_img, 0, 255).astype(np.uint8)\n",
    "else:\n",
    "    # Input normalized 0–1, so scale up\n",
    "    segmented_img = np.clip(segmented_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Save new image to remadeImages folder\n",
    "imsave(os.path.join(output_path, \"Manually Remade Beacon Image.JPEG\"), segmented_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c5bd0f6-fa66-4767-8c59-c04d26595db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second image provided\n",
    "# reading the image\n",
    "img = imread(\"images/elephant.jpg\")\n",
    "\n",
    "# Convert to 2d form\n",
    "img2d = img.reshape(-1,3).astype(np.float64)\n",
    "\n",
    "# Apply the manual KMeans implementation\n",
    "centers, labels = manualKmeans(img2d, k, max_iters = 10)\n",
    "\n",
    "# Reconstruct image\n",
    "segmented_img = centers[labels].reshape(img.shape)\n",
    "\n",
    "# Fix scaling based on dtype, Chat-GPT-3. (2025, Oct. 26)\n",
    "if img.dtype == np.uint8:\n",
    "    # Input already in 0–255, so don't multiply\n",
    "    segmented_img = np.clip(segmented_img, 0, 255).astype(np.uint8)\n",
    "else:\n",
    "    # Input normalized 0–1, so scale up\n",
    "    segmented_img = np.clip(segmented_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Save new image to remadeImages folder\n",
    "imsave(os.path.join(output_path, \"Manually Remade Elephant Image.jpg\"), segmented_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0deed940-53b3-49c3-8217-b02f298ea518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third image provided\n",
    "# reading the image\n",
    "img = imread(\"images/robin.JPEG\")\n",
    "\n",
    "# Convert to 2d form\n",
    "img2d = img.reshape(-1,3).astype(np.float64)\n",
    "\n",
    "# Apply the manual KMeans implementation\n",
    "centers, labels = manualKmeans(img2d, k, max_iters = 10)\n",
    "\n",
    "# Reconstruct image\n",
    "segmented_img = centers[labels].reshape(img.shape)\n",
    "\n",
    "# Fix scaling based on dtype, Chat-GPT-3. (2025, Oct. 26)\n",
    "if img.dtype == np.uint8:\n",
    "    # Input already in 0–255, so don't multiply\n",
    "    segmented_img = np.clip(segmented_img, 0, 255).astype(np.uint8)\n",
    "else:\n",
    "    # Input normalized 0–1, so scale up\n",
    "    segmented_img = np.clip(segmented_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Save new image to remadeImages folder\n",
    "imsave(os.path.join(output_path, \"Manually Remade Robin Image.JPEG\"), segmented_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e96687b0-78ff-4a13-9d7e-2805124f88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth image provided\n",
    "# reading the image\n",
    "img = imread(\"images/vulture.JPEG\")\n",
    "\n",
    "# Convert to 2d form\n",
    "img2d = img.reshape(-1,3).astype(np.float64)\n",
    "\n",
    "# Apply the manual KMeans implementation\n",
    "centers, labels = manualKmeans(img2d, k, max_iters = 10)\n",
    "\n",
    "# Reconstruct image\n",
    "segmented_img = centers[labels].reshape(img.shape)\n",
    "\n",
    "# Fix scaling based on dtype, Chat-GPT-3. (2025, Oct. 26)\n",
    "if img.dtype == np.uint8:\n",
    "    # Input already in 0–255, so don't multiply\n",
    "    segmented_img = np.clip(segmented_img, 0, 255).astype(np.uint8)\n",
    "else:\n",
    "    # Input normalized 0–1, so scale up\n",
    "    segmented_img = np.clip(segmented_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Save new image to remadeImages folder\n",
    "imsave(os.path.join(output_path, \"Manually Remade Vulture Image.JPEG\"), segmented_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d44c20ed-95b1-456f-b51b-a664500d423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fifth image, uploaded by me\n",
    "# reading the image\n",
    "img = imread(\"images/my_cat_Seven.jpg\")\n",
    "\n",
    "# Convert to 2d form\n",
    "img2d = img.reshape(-1,3).astype(np.float64)\n",
    "\n",
    "# Apply the manual KMeans implementation\n",
    "centers, labels = manualKmeans(img2d, k, max_iters = 10)\n",
    "\n",
    "# Reconstruct image\n",
    "segmented_img = centers[labels].reshape(img.shape)\n",
    "\n",
    "# Fix scaling based on dtype, Chat-GPT-3. (2025, Oct. 26)\n",
    "if img.dtype == np.uint8:\n",
    "    # Input already in 0–255, so don't multiply\n",
    "    segmented_img = np.clip(segmented_img, 0, 255).astype(np.uint8)\n",
    "else:\n",
    "    # Input normalized 0–1, so scale up\n",
    "    segmented_img = np.clip(segmented_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Save new image to remadeImages folder\n",
    "imsave(os.path.join(output_path, \"Manually Remade Seven Image.jpg\"), segmented_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417e100-9e9e-4007-9fdc-0a856ab4f2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
