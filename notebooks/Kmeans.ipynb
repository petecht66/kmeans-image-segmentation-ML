{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41090a5a-c4b6-4cb2-bed2-79f768a6f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries and packages\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c84ab1ec-0ee8-47c6-b220-fb65a5aa2264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of image filenames\n",
    "image_files = [\"images/beacon.JPEG\", \"images/elephant.jpg\", \"images/robin.JPEG\", \"images/vulture.JPEG\"]\n",
    "\n",
    "# declare number of clusters, can change this later\n",
    "k = 10\n",
    "\n",
    "# Declare output folder\n",
    "output_path = \"remadeKMeansImages/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00dc7668-1174-4bc5-905a-60729e7ecb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First image provided\n",
    "# reading the image\n",
    "img = imread(\"images/beacon.JPEG\")\n",
    "\n",
    "# Convert to a 2d matrix with number of pixels, number of features\n",
    "img2d = img.reshape(-1, 3)\n",
    "\n",
    "# Reshape array\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "labels = kmeans.fit_predict(img2d)\n",
    "centers = kmeans.cluster_centers_\n",
    "segmented_img = centers[labels].reshape(img.shape)\n",
    "\n",
    "# Fix scaling based on dtype, Chat-GPT-3. (2025, Oct. 26)\n",
    "if img.dtype == np.uint8:\n",
    "    # Input already in 0–255, so don't multiply\n",
    "    segmented_img = np.clip(segmented_img, 0, 255).astype(np.uint8)\n",
    "else:\n",
    "    # Input normalized 0–1, so scale up\n",
    "    segmented_img = np.clip(segmented_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Save new image to remadeImages folder\n",
    "imsave(os.path.join(output_path, \"KMeans Remade Beacon Image.JPEG\"), segmented_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75c09ea0-6293-49fb-828c-8b00ee294dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second image provided\n",
    "# reading the image\n",
    "img = imread(\"images/elephant.jpg\")\n",
    "\n",
    "# Convert to a 2d matrix with number of pixels, number of features\n",
    "img2d = img.reshape(-1, 3)\n",
    "\n",
    "# Reshape array\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "labels = kmeans.fit_predict(img2d)\n",
    "centers = kmeans.cluster_centers_\n",
    "segmented_img = centers[labels].reshape(img.shape)\n",
    "\n",
    "# Fix scaling based on dtype, Chat-GPT-3. (2025, Oct. 26)\n",
    "if img.dtype == np.uint8:\n",
    "    # Input already in 0–255, so don't multiply\n",
    "    segmented_img = np.clip(segmented_img, 0, 255).astype(np.uint8)\n",
    "else:\n",
    "    # Input normalized 0–1, so scale up\n",
    "    segmented_img = np.clip(segmented_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Save new image to remadeImages folder\n",
    "imsave(os.path.join(output_path, \"KMeans Remade Elephant Image.jpg\"), segmented_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e879e921-ef56-49eb-b1b9-72a4fa4e14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third image provided\n",
    "# reading the image\n",
    "img = imread(\"images/robin.JPEG\")\n",
    "\n",
    "# Convert to a 2d matrix with number of pixels, number of features\n",
    "img2d = img.reshape(-1, 3)\n",
    "\n",
    "# Reshape array\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "labels = kmeans.fit_predict(img2d)\n",
    "centers = kmeans.cluster_centers_\n",
    "segmented_img = centers[labels].reshape(img.shape)\n",
    "\n",
    "# Fix scaling based on dtype, Chat-GPT-3. (2025, Oct. 26)\n",
    "if img.dtype == np.uint8:\n",
    "    # Input already in 0–255, so don't multiply\n",
    "    segmented_img = np.clip(segmented_img, 0, 255).astype(np.uint8)\n",
    "else:\n",
    "    # Input normalized 0–1, so scale up\n",
    "    segmented_img = np.clip(segmented_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Save new image to remadeImages folder\n",
    "imsave(os.path.join(output_path, \"KMeans Remade Robin Image.JPEG\"), segmented_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af124da5-29d2-4a09-bbb5-59355c7361b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth image provided\n",
    "# reading the image\n",
    "img = imread(\"images/vulture.JPEG\")\n",
    "\n",
    "# Convert to a 2d matrix with number of pixels, number of features\n",
    "img2d = img.reshape(-1, 3)\n",
    "\n",
    "# Reshape array\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "labels = kmeans.fit_predict(img2d)\n",
    "centers = kmeans.cluster_centers_\n",
    "segmented_img = centers[labels].reshape(img.shape)\n",
    "\n",
    "# Fix scaling based on dtype, Chat-GPT-3. (2025, Oct. 26)\n",
    "if img.dtype == np.uint8:\n",
    "    # Input already in 0–255, so don't multiply\n",
    "    segmented_img = np.clip(segmented_img, 0, 255).astype(np.uint8)\n",
    "else:\n",
    "    # Input normalized 0–1, so scale up\n",
    "    segmented_img = np.clip(segmented_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Save new image to remadeImages folder\n",
    "imsave(os.path.join(output_path, \"KMeans Remade Vulture Image.JPEG\"), segmented_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aeb75b2e-3e06-45c2-b78e-04f08a9f8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fifth image, uploaded by myself\n",
    "# reading the image\n",
    "img = imread(\"images/my_cat_Seven.jpg\")\n",
    "\n",
    "# Convert to a 2d matrix with number of pixels, number of features\n",
    "img2d = img.reshape(-1, 3)\n",
    "\n",
    "# Reshape array\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "labels = kmeans.fit_predict(img2d)\n",
    "centers = kmeans.cluster_centers_\n",
    "segmented_img = centers[labels].reshape(img.shape)\n",
    "\n",
    "# Fix scaling based on dtype, Chat-GPT-3. (2025, Oct. 26)\n",
    "if img.dtype == np.uint8:\n",
    "    # Input already in 0–255, so don't multiply\n",
    "    segmented_img = np.clip(segmented_img, 0, 255).astype(np.uint8)\n",
    "else:\n",
    "    # Input normalized 0–1, so scale up\n",
    "    segmented_img = np.clip(segmented_img * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Save new image to remadeImages folder\n",
    "imsave(os.path.join(output_path, \"KMeans Remade Seven Image.jpg\"), segmented_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0986e-aef3-4bee-990a-413e4a25b2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
